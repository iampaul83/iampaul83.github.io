---
file_name: "_posts/2016-12-02-parquet.md"
layout: post
title:  "使用Parquet"
date:   2016-12-2 00:00:48 +0800
categories: spark datasource
tags: datasource parquet
author: iampaul83
sidebar:
  nav: "spark"
---

今天把Dataframe存成parquet，發現用parquet分析超快的！


## 讀

```scala
val ehaveDF = spark.read
  .parquet("hdfs://namenode-0.hdfs.mesos:9001/parquet/ehave.parquet")
ehaveDF.printSchema
```

這邊有趣的是，似乎把Dataframe存成parquet的時候也有存**schema**資訊（未證實），如果是這樣的話用起來就很方便，不用每次一直搞schama


## 寫

```scala
mongoEhaveDf.write
  .mode("overwrite")
  .parquet("hdfs://namenode-0.hdfs.mesos:9001/parquet/ehave.parquet")
```


## NaN

> mongo的NaN資料型態存到parquet會發生問題

我把mongodb.IEDB.EHAVE_TBL存成parquet的時候，有遇到一個問題：__讀取資料的時候會出現「檔案損壞」的錯誤__。後來發現是只有特定欄位才會有這個錯誤，最後把比較特別的資料型態NaN去掉（改成null）之後，目前是正常使用parquet中。


## 速度比較

> parquet大勝。在這個測試中，因為工作量比較多，即使「轉檔時間＋運算時間」快很多！

我用下面的程式比較mongo與parquet的速度（46次aggregate）

```scala
println("%table\ncolumn\tvalue\tcount")
ehaveDf.schema.fieldNames.foreach { colName =>
  // run 46 times
  val rows = ehaveDF2.groupBy(colName)
    .count
    .sort($"count".desc)
    .take(20)
  printTableRows(colName, rows)
}
```

結果：

```c
mongo          : 3 hr  0 min 44 sec
parquet        :       8 min 14 sec
mongo轉parquet :      10 min  1 sec
```

{% include img src = "assets/images/Screen Shot 2016-12-02 at 2.02.35 PM.png"  w = 1322  h = 764  %}

---

# <a href="http://192.168.2.230/service/zeppelin2/#/notebook/2C292B1WN" class="btn btn--large" target="_black">Check out at Zeppelin Notebook</a>
